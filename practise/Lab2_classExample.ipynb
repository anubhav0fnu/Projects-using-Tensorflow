{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "weights = tf.get_variable(dtype=tf.float32, shape=(), name=\"weights\",\\\n",
    "                        initializer=tf.random_normal_initializer(0.0,1.0))\n",
    "a = tf.constant(2.0, name=\"a\")\n",
    "b = tf.constant(3.0, name=\"b\")\n",
    "c = tf.constant(4.0, name=\"c\")\n",
    "\n",
    "costFunc = tf.add( tf.add(tf.multiply(a,tf.square(weights), name='term1'),tf.multiply(b,weights, name='term2'), name='add_1'),c , name= 'cost_Func')\n",
    "\n",
    "learning_rate=0.01\n",
    "train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(costFunc, name= 'train_step')\n",
    "init = tf.global_variables_initializer()\n",
    "file_writer= tf.summary.FileWriter(\"./datasets/myTensorboardLogs/Lab2_classExample/\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at step 0: [0.55198181, None]\n",
      "Accuracy at step 1: [0.49990255, None]\n",
      "Accuracy at step 2: [0.44990644, None]\n",
      "Accuracy at step 3: [0.40191019, None]\n",
      "Accuracy at step 4: [0.35583377, None]\n",
      "Accuracy at step 5: [0.31160042, None]\n",
      "Accuracy at step 6: [0.2691364, None]\n",
      "Accuracy at step 7: [0.22837093, None]\n",
      "Accuracy at step 8: [0.1892361, None]\n",
      "Accuracy at step 9: [0.15166666, None]\n"
     ]
    }
   ],
   "source": [
    "# I tried Attempting to use \"weights\":  uninitialized value weights--> why this has happened, during graph creation I have initialised the weights with init.\n",
    "# what I think as a reason, that the graph is a static unit, it gets a object allocation when we run init after running a sess.?, Am I right?\n",
    "# then, question comes that, once we called init, it should initialise to some random value, but we get NONE, why?\n",
    "# according to tf doc., the global_variables_initializer() returns an op that initialise global variables. Them, it should return a object of type op instead of NONE.\n",
    "# could you please explain why this is happening?\n",
    "sess = tf.Session()\n",
    "sess.run(fetches=[init])\n",
    "for x in range(10):\n",
    "    acc= sess.run(fetches=[weights,train_step])\n",
    "    print('Accuracy at step %s: %s' % (x, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
